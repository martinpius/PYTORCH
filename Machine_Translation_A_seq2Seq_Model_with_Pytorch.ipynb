{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Translation-A seq2Seq Model with Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORtt8SWAEO3USMs7PR6gUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/PYTORCH/blob/main/Machine_Translation_A_seq2Seq_Model_with_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCh1YRgheog6",
        "outputId": "4928cf17-02ea-481f-b8df-1225218c3c11"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import torch\n",
        "  print(f\"You are on CoLaB with torch version: {torch.__version__}\")\n",
        "except Exception as e:\n",
        "  COLAB = False\n",
        "  print(f\"{type(e)}: {e}\\n>>>>Please correct {type(e)} and re-load your drive\")\n",
        "def time_fmt(t:float = 123.842)->float:\n",
        "  h = int(t / (60 * 60))\n",
        "  m = int(t % (60 * 60) / 60)\n",
        "  s = int(t%60)\n",
        "  return f\"{h}: {m:>02}: {s:>05.2f}\"\n",
        "print(f\">>>>time formating:\\tplease wait....\\n>>>>time elapsed\\t:{time_fmt()}\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "You are on CoLaB with torch version: 1.8.1+cu101\n",
            ">>>>time formating:\tplease wait....\n",
            ">>>>time elapsed\t:0: 02: 03.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BH8rqOUs0pS"
      },
      "source": [
        "#In this notebook we are going to train a Machine translation model\n",
        "#This is a typical sequence to sequence model (where the input is a sequence and output is another sequence)\n",
        "#The architecture of this model is a typical encoder-decoder\n",
        "#We will apply Multi30k datasets from torchtext (using only germany and english columns)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbOrQhHFwD8L"
      },
      "source": [
        "import torch, spacy, time, random, sys,math\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator #For data preprocessing\n",
        "import numpy as np#to set-up the device\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_i6bUKIeydA"
      },
      "source": [
        "#Setup the gpu device to avoid cuda error!!!\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6pR97wRe-tI",
        "outputId": "bf83e113-5ef3-4b5b-93cf-0e47c958ea44"
      },
      "source": [
        "#We start by installing the tokenizers to be used in pre-processing our texts\n",
        "!python -m spacy download en_core_web_sm #For english\n",
        "!python -m spacy download de_core_news_sm #For germany\n",
        "\n",
        "#Loading the tokenizer ready to be used\n",
        "spacy_de = spacy.load('de_core_news_sm') # Restart the kernel to run it effectively\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (56.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoFepdPffMOC"
      },
      "source": [
        "#The following simple functions will take the raw texts and return the list of tokens.\n",
        "#Example: [I love eating -->>> 'I' 'love' 'eating']\n",
        "\n",
        "def tokenize_de(text):\n",
        "  #We also reverse the input sentence to make the model predict more for unseen data (not necessarily mandatory)\n",
        "  return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
        "\n",
        "def tokenize_en(text):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKolmzN6fp1S"
      },
      "source": [
        "#We preprocess the text by applying the above functions, also we mark the start and end of each sentence\n",
        "#To know where to start and where to terminate the predictions ['start of sentence = sos', end of sentence = eos]\n",
        "#We use Field method to perform this tasks(Field also has more parameters (like lower = Bool), etc to add whenever necessary)\n",
        "\n",
        "germany_ln = Field(tokenize = tokenize_de, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "english_ln = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeHfzpvPfucw",
        "outputId": "9610e7ef-c7a5-4357-f975-0877e3297a1b"
      },
      "source": [
        "#We first load our data using Multi30k class (This may take some time to download depending with your internet speed)\n",
        "tic = time.time()\n",
        "print(f\"Please wait while the data is downloaded to CoLaB.....\")\n",
        "train_data, validation_data, test_data = Multi30k.splits(exts = ('.de', '.en'),fields = (germany_ln, english_ln))\n",
        "toc = time.time()\n",
        "print(f\"Time elapsed: {time_fmt(toc - tic)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please wait while the data is downloaded to CoLaB.....\n",
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.21M/1.21M [00:04<00:00, 284kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.3k/46.3k [00:00<00:00, 91.9kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.2k/66.2k [00:00<00:00, 85.9kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time elapsed: 0: 31: 31.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqdKPShpf1NJ"
      },
      "source": [
        "#We build vocabulary for only training data to avoid falacy during validation and testing\n",
        "#We keep those tokens which occurs at least twice\n",
        "germany_ln.build_vocab(train_data, min_freq = 2)\n",
        "english_ln.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJMy_O68f-Ht"
      },
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh4VAMBogJgi"
      },
      "source": [
        "#We can then build our iterator that will be used to stream in our model ready for training\n",
        "#We also alocate the iterator to the gpu when available\n",
        "batch_size = 64\n",
        "train_iterator, validation_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, validation_data, test_data), \n",
        "    batch_size = batch_size, \n",
        "    device = device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tnGXzjtgLBW"
      },
      "source": [
        "#We build our model in 3 stages: Encoder, Decoder and AutoEncoder(Model)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_tX8yX99-Ay"
      },
      "source": [
        "#The Encoder Class: Is the ussual RNN with 2 LSTM layers\n",
        "#The input dimension = len(germary_vocabulary), We consider \n",
        "#The embedding layer of 300 dimension and the hidden size of 1024 neurons\n",
        "#The return from this class is the context vectors(hidden and cell states)\n",
        "#To be used as additional inputs to our decoder network later on\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, embd_dim, hidden_size, num_layers, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.embedding = nn.Embedding(input_dim, embd_dim)\n",
        "    self.rnn = nn.LSTM(embd_dim, hidden_size, num_layers, dropout = dropout)\n",
        "  \n",
        "  def forward(self, input_tensor):\n",
        "    #input_tensor_shape: [len_germany_vocab, batch_size]\n",
        "    x = self.dropout(self.embedding(input_tensor))\n",
        "    output, (hidden, cell) = self.rnn(x)\n",
        "    #Hidden, cell shape = [num_layers, batch_size, hidden_dim]\n",
        "    return hidden, cell\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rUVwCArgpod"
      },
      "source": [
        "#The decoder class: Is also an rnn with 2 LSTM layers that takes\n",
        "#inputs of size [1-token at a time] and context vector from the encoder\n",
        "#We have an additional fully connected layer for the output\n",
        "#The output of this class will be the predictions, cell and hidden states\n",
        "#To be fed to the next prediction as input (since we will predict one token at a time)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, embd_dim, hidden_size, num_layers, dropout):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.output_dim = output_dim\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.embedding = nn.Embedding(output_dim, embd_dim)\n",
        "    self.rnn = nn.LSTM(embd_dim, hidden_size, num_layers, dropout = dropout)\n",
        "    self.fc = nn.Linear(hidden_size, output_dim)\n",
        "  \n",
        "  def forward(self, input_tensor, hidden, cell):\n",
        "    #input tensor shape [batch_size]\n",
        "    #We need to make sure we enter one token at a time\n",
        "    input_tensor = input_tensor.unsqueeze(0) #Force the shape to be [1,batch_size]\n",
        "    embedded = self.dropout(self.embedding(input_tensor)) #shape = (1, batch_size, emb_dim)\n",
        "    output, (hidden, cell) = self.rnn(embedded, (hidden, cell)) # output shape: (1, batch_size, hidden_dm*1d))\n",
        "    predictions = self.fc(output.squeeze(0))# predictions (unsqueezed = [batch_size, hidden_dim]) so we squeeze back to [batch_size]\n",
        "    return predictions, hidden, cell"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMtzH6BThRqD"
      },
      "source": [
        "#We are ready to construct the model class by simply linking the two classes above\n",
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self, encoder, decoder, device):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "  \n",
        "  def forward(self, input_tensor, target, teacher_forcing_ratio = 0.5):\n",
        "    '''\n",
        "    this method will build a prediction with the help of teacher-forcing\n",
        "    technique(we provide the ground truth 50% chance as input to the next \n",
        "    time stamp) else we feed the predicted output as input for the next token\n",
        "    prediction. if prob = 1 then the model wont be able to generalize for the test/validation\n",
        "    '''\n",
        "    batch_size = target.shape[1] # we know the shape of target = [len(english_voc), batch_size]\n",
        "    target_len = target.shape[0] #target = [len(english_voc), batch_size]\n",
        "    target_voc_size = self.decoder.output_dim #we grab the dimension of target (len(english_vocabulary)\n",
        "    outputs = torch.zeros(target_len, batch_size, target_voc_size).to(self.device) #Container for the predictions\n",
        "    hidden, cell = self.encoder(input_tensor) #We simply run the encoder to get the context for the initial input to decoder\n",
        "    input = target[0,:] # grab one token at a time for the decoder\n",
        "    for t in range(1, target_len):\n",
        "      output, hidden, cell = self.decoder(input, hidden, cell) #We now run the decoder for every token until the end os a sentence\n",
        "      outputs[t] = output #assigning to the container\n",
        "      #Applying teacher forcing if the condition is satisfied else use best guess = previous output\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "      best_guess = output.argmax(1)\n",
        "      input = target[t] if teacher_force else best_guess\n",
        "    return outputs\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMw-p2GzidFj"
      },
      "source": [
        "#Hyper-parameters for the Model\n",
        "input_dim = len(germany_ln.vocab)\n",
        "output_dim = len(english_ln.vocab)\n",
        "enc_embd_dim = 256\n",
        "dec_embd_dim = 256\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "enc_dropout, dec_dropout = 0.5, 0.5"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSeSFSBqXAVv"
      },
      "source": [
        "enc = Encoder(input_dim,enc_embd_dim,hidden_size,num_layers, enc_dropout)\n",
        "dec = Decoder(output_dim, dec_embd_dim,hidden_size, num_layers, dec_dropout)\n",
        "\n",
        "model = AutoEncoder(enc, dec, device).to(device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdpQ1aOGik-8",
        "outputId": "a1eba4b3-07ee-46af-d5a9-486a06ea679a"
      },
      "source": [
        "\n",
        "#We initialize all parameters to uniform distribution in range[-0.08, 0.08]\n",
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights) #apply the function to initialize the parameters of the model to a uniform distribution"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoEncoder(\n",
              "  (encoder): Encoder(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc): Linear(in_features=512, out_features=5893, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_meeYOojB6j"
      },
      "source": [
        "#Get the optimizer and loss objects\n",
        "#We exclude padded indices (we are not going to incur any cost due to padding)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "pad_idx = english_ln.vocab.stoi[english_ln.pad_token] #grab all padded indices\n",
        "loss_obj = nn.CrossEntropyLoss(ignore_index = pad_idx)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCX-QkCDjPHQ"
      },
      "source": [
        "#The training function help us for the training loop\n",
        "def train(model, iterator, optimizer, loss_obj, clip):\n",
        "  model.train() #to activate the regularizer layers such as batchnorm/dropout\n",
        "  epoch_loss = 0\n",
        "  for i, batch in enumerate(iterator):\n",
        "    src = batch.src #grab the input tensor (related to germany tokens)\n",
        "    trg = batch.trg #grab the target tensor (related to english token)\n",
        "    optimizer.zero_grad() # initialize the grads for the wt to zeros\n",
        "    output = model(src, trg) #Ussual forward pass \n",
        "    output_dim = output.shape[-1] # output_shap: [1,batch, target_dim]\n",
        "    output = output[1:].view(-1, output_dim) #grab from 2nd token and shrink the dimension to [1*batch, target_dim]\n",
        "    trg = trg[1:].view(-1) #do the same as above (reshaping the target)\n",
        "    loss = loss_obj(output, trg) #compute train loss\n",
        "    loss.backward() #backward pass as ussual\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)#cliping the gradient to avoid explosion \n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kkGgOlVjtzF"
      },
      "source": [
        "#Evaluation loop\n",
        "def evaluate(model, iterator, loss_obj):\n",
        "  model.eval() # turn off regularizers\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():#No need to re-compute the gradient again\n",
        "    for i, batch in enumerate(iterator):\n",
        "      src = batch.src\n",
        "      trg = batch.trg\n",
        "      output = model(src, trg, 0) #turn off teacher forcing\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output[1:].view(-1, output_dim)\n",
        "      trg = trg[1:].view(-1)\n",
        "      loss = loss_obj(output, trg)\n",
        "      epoch_loss += loss.item()\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gtyNn-IkS5T",
        "outputId": "8a7acf7c-0afe-4df9-fecb-9b348967ef77"
      },
      "source": [
        "#We finally training our model for 100 epochs \n",
        "num_epochs = 100\n",
        "clip = 1 #for clipping the gradient\n",
        "best_valid_loss = float('inf') #to check if an epoch has achieved a best validation loss\n",
        "for epoch in range(num_epochs):\n",
        "  tic = time.time()\n",
        "  train_loss = train(model, train_iterator, optimizer,loss_obj,clip)\n",
        "  valid_loss = evaluate(model, validation_iterator, loss_obj)\n",
        "  toc = time.time()\n",
        "  epoch_time = time_fmt(toc-tic)\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'mtl_model.pt')\n",
        "    \n",
        "  print(f'Epoch: {epoch+1:02} | Time elapsed: {epoch_time}')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "  print(f'\\tValidation. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 4.172 | Train PPL:  64.825\n",
            "\tValidation. Loss: 4.514 |  Val. PPL:  91.329\n",
            "Epoch: 02 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 3.879 | Train PPL:  48.384\n",
            "\tValidation. Loss: 4.317 |  Val. PPL:  74.945\n",
            "Epoch: 03 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 3.668 | Train PPL:  39.173\n",
            "\tValidation. Loss: 4.096 |  Val. PPL:  60.105\n",
            "Epoch: 04 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 3.455 | Train PPL:  31.667\n",
            "\tValidation. Loss: 4.007 |  Val. PPL:  55.003\n",
            "Epoch: 05 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 3.276 | Train PPL:  26.469\n",
            "\tValidation. Loss: 3.922 |  Val. PPL:  50.508\n",
            "Epoch: 06 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 3.128 | Train PPL:  22.838\n",
            "\tValidation. Loss: 3.835 |  Val. PPL:  46.284\n",
            "Epoch: 07 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 2.996 | Train PPL:  20.007\n",
            "\tValidation. Loss: 3.769 |  Val. PPL:  43.337\n",
            "Epoch: 08 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 2.871 | Train PPL:  17.654\n",
            "\tValidation. Loss: 3.810 |  Val. PPL:  45.168\n",
            "Epoch: 09 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 2.773 | Train PPL:  16.002\n",
            "\tValidation. Loss: 3.687 |  Val. PPL:  39.916\n",
            "Epoch: 10 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 2.647 | Train PPL:  14.114\n",
            "\tValidation. Loss: 3.706 |  Val. PPL:  40.687\n",
            "Epoch: 11 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 2.562 | Train PPL:  12.962\n",
            "\tValidation. Loss: 3.710 |  Val. PPL:  40.859\n",
            "Epoch: 12 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 2.461 | Train PPL:  11.721\n",
            "\tValidation. Loss: 3.695 |  Val. PPL:  40.254\n",
            "Epoch: 13 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 2.358 | Train PPL:  10.575\n",
            "\tValidation. Loss: 3.675 |  Val. PPL:  39.434\n",
            "Epoch: 14 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 2.294 | Train PPL:   9.910\n",
            "\tValidation. Loss: 3.711 |  Val. PPL:  40.895\n",
            "Epoch: 15 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 2.219 | Train PPL:   9.197\n",
            "\tValidation. Loss: 3.747 |  Val. PPL:  42.412\n",
            "Epoch: 16 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 2.143 | Train PPL:   8.521\n",
            "\tValidation. Loss: 3.665 |  Val. PPL:  39.051\n",
            "Epoch: 17 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 2.068 | Train PPL:   7.912\n",
            "\tValidation. Loss: 3.712 |  Val. PPL:  40.949\n",
            "Epoch: 18 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.997 | Train PPL:   7.368\n",
            "\tValidation. Loss: 3.781 |  Val. PPL:  43.840\n",
            "Epoch: 19 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.926 | Train PPL:   6.865\n",
            "\tValidation. Loss: 3.783 |  Val. PPL:  43.927\n",
            "Epoch: 20 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.869 | Train PPL:   6.484\n",
            "\tValidation. Loss: 3.785 |  Val. PPL:  44.046\n",
            "Epoch: 21 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.824 | Train PPL:   6.197\n",
            "\tValidation. Loss: 3.811 |  Val. PPL:  45.216\n",
            "Epoch: 22 | Time elapsed: 0: 01: 31.00\n",
            "\tTrain Loss: 1.765 | Train PPL:   5.840\n",
            "\tValidation. Loss: 3.833 |  Val. PPL:  46.181\n",
            "Epoch: 23 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.715 | Train PPL:   5.555\n",
            "\tValidation. Loss: 3.823 |  Val. PPL:  45.733\n",
            "Epoch: 24 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.672 | Train PPL:   5.320\n",
            "\tValidation. Loss: 3.947 |  Val. PPL:  51.777\n",
            "Epoch: 25 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.629 | Train PPL:   5.099\n",
            "\tValidation. Loss: 3.891 |  Val. PPL:  48.977\n",
            "Epoch: 26 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.571 | Train PPL:   4.813\n",
            "\tValidation. Loss: 3.945 |  Val. PPL:  51.654\n",
            "Epoch: 27 | Time elapsed: 0: 01: 32.00\n",
            "\tTrain Loss: 1.526 | Train PPL:   4.601\n",
            "\tValidation. Loss: 3.947 |  Val. PPL:  51.785\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}