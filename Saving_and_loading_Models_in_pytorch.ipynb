{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saving and loading Models in pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkfCZHWzB5mmSbqVgf3BuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/PYTORCH/blob/main/Saving_and_loading_Models_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Q2aVbuDinX",
        "outputId": "1425f307-139d-4f16-bf0b-c25ee158453a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import torch\n",
        "  print(f\"You are on Google CoLaB with torch version: {torch.__version__}\")\n",
        "except Exception as e:\n",
        "  print(f\"{type(e)}: {e}\\n>>>please load your drive properly...\")\n",
        "  COLAB = False\n",
        "#Assigning GPU device when available:\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "def time_fmt(t:float = 123.817)->float:\n",
        "  h = int(t / (60 * 60))\n",
        "  m = int(t % (60 * 60) / 60)\n",
        "  s = int(t % 60)\n",
        "  return f\"{h}: {m:>02}: {s:>05.2f}\"\n",
        "print(f\">>>time testing\\tplease wait...\\ntime elapse:\\t{time_fmt()}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "You are on Google CoLaB with torch version: 1.8.1+cu101\n",
            ">>>time testing\tplease wait...\n",
            "time elapse:\t0: 02: 03.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1NidXTSFQE8"
      },
      "source": [
        "#In this short tutorial we are going to learn how to create a simple deep learning model in torch,\n",
        "#saving the model into the device of our choice and then loading back the model whenerver needed:\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tHrsEfEH_2V"
      },
      "source": [
        "#For demo, we train a simple cnn to classify mnist images:"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FoV3eIRI2Bd"
      },
      "source": [
        "#Importing neccessary libraries and modules from torch\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.transforms import transforms\n",
        "from tqdm import tqdm\n",
        "import time, datetime, sys, os"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rjONnOJf77"
      },
      "source": [
        "#Model's hyperparameters:\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "in_channels = 1\n",
        "num_classes = 10\n",
        "learning_rate = 1e-3\n",
        "load_model = True"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjiJGqTHKBhR"
      },
      "source": [
        "#Creating the simple cnn using the following class:\n",
        "class CNNBLOCK(nn.Module):\n",
        "  def __init__(self, in_channels = 1, num_classes = 10, *args, **kwargs):\n",
        "    super(CNNBLOCK, self).__init__(*args, **kwargs)\n",
        "    self.conv1 = nn.Conv2d(in_channels = in_channels, \n",
        "                           out_channels = 8, \n",
        "                           kernel_size = (3,3),\n",
        "                           stride = (1,1), \n",
        "                           padding = (1,1))\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2))\n",
        "    self.conv2 = nn.Conv2d(in_channels = 8, \n",
        "                           out_channels = 16, \n",
        "                           kernel_size = (3,3), \n",
        "                           stride = (1,1), \n",
        "                           padding = (1,1))\n",
        "    self.fc1 = nn.Linear(in_features = 16*7*7, out_features = 256)\n",
        "    self.fc2 = nn.Linear(in_features = 256, out_features = num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    return self.fc2(x)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBo3_un1MXXp"
      },
      "source": [
        "#Instantiating our model class:\n",
        "model = CNNBLOCK().to(device)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKilhV_2PEwi",
        "outputId": "9465f9fb-5b11-4fa3-c2a8-2cf6280b9de6"
      },
      "source": [
        "#Loading the data from torch:\n",
        "train_data = datasets.MNIST(root = 'train_dataset/', train = True, transform = transforms.ToTensor(), download = True)\n",
        "test_data = datasets.MNIST(root = 'test_dataset/', train = False, transform = transforms.ToTensor(), download = True)\n",
        "train_loader = DataLoader(dataset = train_data, shuffle = True, batch_size = batch_size)\n",
        "test_loader = DataLoader(dataset = test_data, shuffle = True, batch_size = batch_size)\n",
        "x_train_batch, y_train_batch = next(iter(train_loader))\n",
        "print(f\"x_batch_shape: {x_train_batch.shape}, y_batch_shape: {y_train_batch.shape}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_batch_shape: torch.Size([64, 1, 28, 28]), y_batch_shape: torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKX5ji2Zj5ms"
      },
      "source": [
        "def save_checkpoint(state, filename = 'my_checkpoint.pth.tar'):\n",
        "  print(\">>>saving model checkpoint:\")\n",
        "  torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint):\n",
        "  print(\">>>>Loading model's checkpoint:\")\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_dict'])\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVjRH8iE2z7p",
        "outputId": "59fd4bf6-8315-4603-a6df-ebc63ec7785b"
      },
      "source": [
        "#Getting loss and optimizer objects\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "#Loading checkpoint if any\n",
        "if load_model:\n",
        "  load_checkpoint(torch.load('my_checkpoint.pth.tar'))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>>Loading model's checkpoint:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCCUxwaacPJn",
        "outputId": "9b481bd8-3c76-47b2-82cb-2c84ee93ca31"
      },
      "source": [
        "#training loop:\n",
        "tic = time.time()\n",
        "for epoch in range(epochs):\n",
        "  losses = []\n",
        "  print(f\">>>train starts for epoch: {epoch}\\n>>>train on progress:\\tplease wait while the model is training...\")\n",
        "  if epoch %2  == 0:\n",
        "    checkpoint = {'state_dict': model.state_dict(),'optimizer_dict': optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint)\n",
        "  for idx, (data, target) in enumerate(tqdm(train_loader)):\n",
        "    #assign the data to the gpu device if available\n",
        "    data = data.to(device = device)\n",
        "    target = target.to(device = device)\n",
        "    #forwad pass\n",
        "    preds = model(data)\n",
        "    train_loss = loss_fn(preds, target)\n",
        "    losses.append(train_loss.item())\n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    #gradient discent using RMSprop with lr of 1e-3\n",
        "    optimizer.step()\n",
        "  mean_loss = sum(losses)/len(losses)\n",
        "  print(f\">>>At epoch {epoch+1}: the mean loss is: {float(mean_loss):.4f}\")\n",
        "#Monitoring metrics for the train and validation data\n",
        "def _evaluate_model_(loader, model):\n",
        "  if loader.dataset.train:\n",
        "    print(f\"Checking metrics for the training set\\n>>>please wait\\tchecking on progress...\")\n",
        "  else:\n",
        "    print(f\"Checking metrics for the validation set\\n>>>please wait\\checking on progress...\")\n",
        "  num_correct = 0\n",
        "  num_examples = 0\n",
        "  model.eval()\n",
        "  #no need to recompute grads\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      preds = model(x)\n",
        "      _, predictions = preds.max(1) #maximum proba in a set of 10 classes\n",
        "      num_correct+=(predictions ==y).sum()\n",
        "      num_examples+=predictions.size(0)\n",
        "  model.train()\n",
        "  return num_correct/num_examples\n",
        "toc = time.time()\n",
        "print(f\"Accuracy for the training data is {float(_evaluate_model_(train_loader, model))*100:.2f}\")\n",
        "print(f\"Accuracy for the validation data is {float(_evaluate_model_(test_loader, model))*100:.2f}\")\n",
        "print(f\"\\n>>>training and evaluation time is : {time_fmt(toc - tic)}\")\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 18/938 [00:00<00:05, 173.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>train starts for epoch: 0\n",
            ">>>train on progress:\tplease wait while the model is training...\n",
            ">>>saving model checkpoint:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 176.59it/s]\n",
            "  2%|▏         | 19/938 [00:00<00:05, 172.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 1: the mean loss is: 0.0025\n",
            ">>>train starts for epoch: 1\n",
            ">>>train on progress:\tplease wait while the model is training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 163.71it/s]\n",
            "  2%|▏         | 15/938 [00:00<00:06, 141.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 2: the mean loss is: 0.0021\n",
            ">>>train starts for epoch: 2\n",
            ">>>train on progress:\tplease wait while the model is training...\n",
            ">>>saving model checkpoint:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 172.13it/s]\n",
            "  1%|▏         | 13/938 [00:00<00:07, 126.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 3: the mean loss is: 0.0020\n",
            ">>>train starts for epoch: 3\n",
            ">>>train on progress:\tplease wait while the model is training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 160.16it/s]\n",
            "  2%|▏         | 19/938 [00:00<00:04, 186.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 4: the mean loss is: 0.0023\n",
            ">>>train starts for epoch: 4\n",
            ">>>train on progress:\tplease wait while the model is training...\n",
            ">>>saving model checkpoint:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 164.61it/s]\n",
            "  2%|▏         | 15/938 [00:00<00:06, 143.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 5: the mean loss is: 0.0021\n",
            ">>>train starts for epoch: 5\n",
            ">>>train on progress:\tplease wait while the model is training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 158.50it/s]\n",
            "  2%|▏         | 18/938 [00:00<00:05, 173.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 6: the mean loss is: 0.0022\n",
            ">>>train starts for epoch: 6\n",
            ">>>train on progress:\tplease wait while the model is training...\n",
            ">>>saving model checkpoint:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:06<00:00, 152.74it/s]\n",
            "  2%|▏         | 15/938 [00:00<00:06, 141.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 7: the mean loss is: 0.0025\n",
            ">>>train starts for epoch: 7\n",
            ">>>train on progress:\tplease wait while the model is training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 158.09it/s]\n",
            "  2%|▏         | 18/938 [00:00<00:05, 178.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 8: the mean loss is: 0.0026\n",
            ">>>train starts for epoch: 8\n",
            ">>>train on progress:\tplease wait while the model is training...\n",
            ">>>saving model checkpoint:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 175.51it/s]\n",
            "  2%|▏         | 19/938 [00:00<00:04, 184.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 9: the mean loss is: 0.0025\n",
            ">>>train starts for epoch: 9\n",
            ">>>train on progress:\tplease wait while the model is training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:05<00:00, 175.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>At epoch 10: the mean loss is: 0.0023\n",
            "Checking metrics for the training set\n",
            ">>>please wait\tchecking on progress...\n",
            "Accuracy for the training data is 99.91\n",
            "Checking metrics for the validation set\n",
            ">>>please wait\\checking on progress...\n",
            "Accuracy for the validation data is 99.07\n",
            "\n",
            ">>>training and evaluation time is : 0: 00: 56.00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}